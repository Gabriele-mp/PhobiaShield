{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üõ°Ô∏è PhobiaShield - Training Notebook\n",
    "\n",
    "**Custom Object Detection from Scratch**\n",
    "\n",
    "Questo notebook permette di addestrare PhobiaNet su Google Colab con GPU.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Setup Checklist\n",
    "\n",
    "1. ‚úÖ **Runtime**: GPU (T4 recommended)\n",
    "2. ‚úÖ **W&B Account**: Per tracking esperimenti\n",
    "3. ‚úÖ **GitHub Repo**: Clonata localmente\n",
    "4. ‚úÖ **Dataset**: Scaricato e preparato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/your-team/PhobiaShield.git\n",
    "%cd PhobiaShield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Weights & Biases Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# Login to W&B (inserisci la tua API key)\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Download & Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "# TODO: Aggiungere script di download dataset\n",
    "# Per ora, assumiamo che il dataset sia gi√† disponibile\n",
    "\n",
    "!mkdir -p data/raw data/processed data/annotations\n",
    "print(\"Dataset directories created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Quick Test: Load Data & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset loading\n",
    "from src.data.dataset import PhobiaDataset, get_transforms\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Load config\n",
    "cfg = OmegaConf.load(\"cfg/config.yaml\")\n",
    "data_cfg = OmegaConf.load(\"cfg/data/coco_phobia.yaml\")\n",
    "\n",
    "# Create dummy dataset for testing\n",
    "print(\"Testing dataset class...\")\n",
    "# dataset = PhobiaDataset(...)\n",
    "print(\"‚úì Dataset class works!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model creation\n",
    "from src.models.phobia_net import create_model\n",
    "\n",
    "# Load model config\n",
    "model_cfg = OmegaConf.load(\"cfg/model/tiny_yolo.yaml\")\n",
    "model_cfg = OmegaConf.to_container(model_cfg, resolve=True)\n",
    "\n",
    "# Create model\n",
    "model = create_model(model_cfg)\n",
    "model = model.cuda() if torch.cuda.is_available() else model\n",
    "\n",
    "# Test forward pass\n",
    "x = torch.randn(2, 3, 416, 416)\n",
    "x = x.cuda() if torch.cuda.is_available() else x\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(\"‚úì Model works!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loss function\n",
    "from src.models.loss import PhobiaLoss\n",
    "\n",
    "# Create loss\n",
    "criterion = PhobiaLoss(\n",
    "    lambda_coord=5.0,\n",
    "    lambda_obj=1.0,\n",
    "    lambda_noobj=0.5,\n",
    "    lambda_class=1.0,\n",
    "    grid_size=13,\n",
    "    num_boxes=2,\n",
    "    num_classes=3,\n",
    ")\n",
    "\n",
    "# Create dummy target\n",
    "target = torch.zeros(2, 13, 13, 2 * 5 + 3)\n",
    "target = target.cuda() if torch.cuda.is_available() else target\n",
    "\n",
    "# Compute loss\n",
    "loss, loss_dict = criterion(output, target)\n",
    "\n",
    "print(\"Loss components:\")\n",
    "for key, value in loss_dict.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"‚úì Loss function works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: Fast Test (5 epochs, subset of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test training\n",
    "!python scripts/train.py \\\n",
    "    model=baseline \\\n",
    "    training=fast_test \\\n",
    "    training.device=cuda \\\n",
    "    wandb.name=fast-test-run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full training with Tiny-YOLO\n",
    "!python scripts/train.py \\\n",
    "    model=tiny_yolo \\\n",
    "    training=default \\\n",
    "    training.epochs=100 \\\n",
    "    training.batch_size=16 \\\n",
    "    training.device=cuda \\\n",
    "    wandb.name=tiny-yolo-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option C: Custom Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom configuration\n",
    "!python scripts/train.py \\\n",
    "    model=tiny_yolo \\\n",
    "    training=default \\\n",
    "    training.epochs=50 \\\n",
    "    training.batch_size=8 \\\n",
    "    training.optimizer.lr=0.001 \\\n",
    "    training.device=cuda \\\n",
    "    wandb.name=custom-run-lr001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Monitor Training\n",
    "\n",
    "Vai su [Weights & Biases](https://wandb.ai) per monitorare il training in tempo reale!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and evaluate\n",
    "import torch\n",
    "from src.models.phobia_net import create_model\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Load config\n",
    "model_cfg = OmegaConf.load(\"cfg/model/tiny_yolo.yaml\")\n",
    "model_cfg = OmegaConf.to_container(model_cfg, resolve=True)\n",
    "\n",
    "# Create model\n",
    "model = create_model(model_cfg)\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(\"outputs/checkpoints/best_model.pth\")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model = model.cuda() if torch.cuda.is_available() else model\n",
    "model.eval()\n",
    "\n",
    "print(\"‚úì Model loaded successfully!\")\n",
    "print(f\"Best validation loss: {checkpoint['best_val_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference on sample image\n",
    "from src.inference.nms import nms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO: Add visualization code\n",
    "print(\"Ready for inference!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Download Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download checkpoint to local\n",
    "from google.colab import files\n",
    "\n",
    "# Download best model\n",
    "files.download(\"outputs/checkpoints/best_model.pth\")\n",
    "\n",
    "print(\"‚úì Checkpoint downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Push to GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure git\n",
    "!git config --global user.email \"your-email@example.com\"\n",
    "!git config --global user.name \"Your Name\"\n",
    "\n",
    "# Add, commit, push\n",
    "!git add .\n",
    "!git commit -m \"feat: training results from Colab\"\n",
    "!git push origin your-branch-name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Useful Commands\n",
    "\n",
    "```bash\n",
    "# Monitor GPU usage\n",
    "!nvidia-smi\n",
    "\n",
    "# Check disk space\n",
    "!df -h\n",
    "\n",
    "# List checkpoints\n",
    "!ls -lh outputs/checkpoints/\n",
    "\n",
    "# View config\n",
    "!cat cfg/config.yaml\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Tips\n",
    "\n",
    "1. **Save checkpoints frequently** - Colab pu√≤ disconnettersi\n",
    "2. **Usa W&B** - Per non perdere le metriche\n",
    "3. **Batch size** - Riduci se vai out of memory\n",
    "4. **Learning rate** - Parti da 0.001 e riduci se la loss non scende\n",
    "5. **Validation** - Monitora overfitting\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Training! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
