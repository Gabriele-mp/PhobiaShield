{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PhobiaShield - Complete Training Pipeline\n",
    "**The Architect Module**\n",
    "\n",
    "1. Download mini dataset\n",
    "2. Train PhobiaNet\n",
    "3. Test on real data\n",
    "\n",
    "**Setup:** Runtime > GPU (T4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Clone repo\n",
    "!git clone https://github.com/Gabriele-mp/PhobiaShield.git\n",
    "%cd PhobiaShield\n",
    "!git checkout TheArchitect\n",
    "!pip install -q -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Check\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download Mini Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download COCO mini dataset\n",
    "!python scripts/download_mini_dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Quick Test Training (5 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast test training\n",
    "!python scripts/train_complete.py training=fast_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Full Training (50 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full training (uncomment to run)\n",
    "# !python scripts/train_complete.py training.epochs=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Test on Real Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model and test\n",
    "from omegaconf import OmegaConf\n",
    "from src.models.phobia_net import PhobiaNet\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Load model\n",
    "model_cfg = OmegaConf.load('cfg/model/tiny_yolo.yaml')\n",
    "model = PhobiaNet(model_cfg).to(device)\n",
    "\n",
    "# Load best weights\n",
    "checkpoint = torch.load('outputs/checkpoints/best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(\"✓ Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on random validation images\n",
    "import torchvision.transforms as T\n",
    "import cv2\n",
    "\n",
    "# Get test images\n",
    "test_images = list(Path('data/mini_dataset/test/images').glob('*.jpg'))[:6]\n",
    "\n",
    "# Transform\n",
    "transform = T.Compose([\n",
    "    T.Resize((416, 416)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "# Class names\n",
    "class_names = ['Clown', 'Shark', 'Spider']\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, img_path in enumerate(test_images):\n",
    "    # Load image\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        predictions = model.predict(img_tensor, conf_threshold=0.5)\n",
    "    \n",
    "    # Draw\n",
    "    img_np = np.array(img)\n",
    "    \n",
    "    for pred in predictions[0]:  # First image in batch\n",
    "        x, y, w, h = pred['bbox']\n",
    "        conf = pred['confidence']\n",
    "        cls = pred['class_id']\n",
    "        \n",
    "        # Convert to pixel coords\n",
    "        h_img, w_img = img_np.shape[:2]\n",
    "        x1 = int((x - w/2) * w_img)\n",
    "        y1 = int((y - h/2) * h_img)\n",
    "        x2 = int((x + w/2) * w_img)\n",
    "        y2 = int((y + h/2) * h_img)\n",
    "        \n",
    "        # Draw bbox\n",
    "        cv2.rectangle(img_np, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(img_np, f\"{class_names[cls]} {conf:.2f}\", \n",
    "                   (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    axes[idx].imshow(img_np)\n",
    "    axes[idx].axis('off')\n",
    "    axes[idx].set_title(f\"Detections: {len(predictions[0])}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Inference complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mAP on test set\n",
    "from src.training.metrics import calculate_map\n",
    "from src.data.phobia_dataset import PhobiaDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = PhobiaDataset(\n",
    "    img_dir='data/mini_dataset/test/images',\n",
    "    label_dir='data/mini_dataset/test/labels',\n",
    "    img_size=416,\n",
    "    grid_size=13,\n",
    "    num_boxes=2,\n",
    "    num_classes=3,\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"Calculating mAP on test set...\")\n",
    "map_score = calculate_map(model, test_loader, device, iou_threshold=0.5)\n",
    "print(f\"\\nmAP@0.5: {map_score:.4f}\")\n",
    "print(\"\\n✅ All done!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
