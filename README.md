# ğŸ›¡ï¸ PhobiaShield: Custom Object Detection for Phobia Management

**PhobiaShield** Ã¨ un sistema di Object Detection "from scratch" progettato per rilevare e offuscare automaticamente oggetti fobici nei video (ragni, serpenti, sangue).

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ“‹ Indice

- [Panoramica del Progetto](#panoramica-del-progetto)
- [Architettura](#architettura)
- [Struttura del Repository](#struttura-del-repository)
- [Setup e Installazione](#setup-e-installazione)
- [Utilizzo](#utilizzo)
- [Team e Ruoli](#team-e-ruoli)
- [Roadmap di Sviluppo](#roadmap-di-sviluppo)
- [Contribuire](#contribuire)

---

## ğŸ¯ Panoramica del Progetto

### Obiettivi
- **Object Detection Custom**: Implementare una rete neurale "from scratch" (no ultralytics/detectron2)
- **Classi Target**: Spider, Snake, Blood (espandibile in futuro)
- **Output**: Demo interattiva su trailer cinematografici + Report accademico
- **Timeline**: 14 giorni di sviluppo intensivo

### Tecnologie Chiave
- **Framework**: PyTorch puro (no librerie high-level di detection)
- **Experiment Tracking**: Weights & Biases (wandb)
- **Configuration Management**: Hydra
- **Training**: PyTorch Lightning (opzionale per semplificare training loop)
- **Video Processing**: OpenCV
- **Demo Interface**: Streamlit/Gradio

---

## ğŸ—ï¸ Architettura

### Modello: Tiny-YOLO Semplificato

```
Input (416x416x3)
    â†“
Conv2d(16) â†’ BatchNorm â†’ LeakyReLU â†’ MaxPool
    â†“
Conv2d(32) â†’ BatchNorm â†’ LeakyReLU â†’ MaxPool
    â†“
Conv2d(64) â†’ BatchNorm â†’ LeakyReLU â†’ MaxPool
    â†“
Conv2d(128) â†’ BatchNorm â†’ LeakyReLU â†’ MaxPool
    â†“
Conv2d(256) â†’ BatchNorm â†’ LeakyReLU â†’ MaxPool
    â†“
Conv2d(512) â†’ BatchNorm â†’ LeakyReLU
    â†“
Output Conv2d: Grid SxS Ã— (B*5 + C)
```

### Loss Function Custom
La loss combina tre componenti:
1. **Localization Loss** (MSE): Coordinate delle bounding box
2. **Confidence Loss** (BCE): Presenza/assenza oggetto
3. **Classification Loss** (CE): Classe dell'oggetto

---

## ğŸ“ Struttura del Repository

```
PhobiaShield/
â”œâ”€â”€ README.md                   # Questo file
â”œâ”€â”€ requirements.txt            # Dipendenze Python
â”œâ”€â”€ setup.py                    # Setup del package
â”œâ”€â”€ .gitignore                 # File da ignorare in git
â”‚
â”œâ”€â”€ cfg/                       # ğŸ”§ Configurazioni Hydra
â”‚   â”œâ”€â”€ config.yaml           # Config principale
â”‚   â”œâ”€â”€ model/                # Config modello
â”‚   â”‚   â”œâ”€â”€ tiny_yolo.yaml
â”‚   â”‚   â””â”€â”€ baseline.yaml
â”‚   â”œâ”€â”€ data/                 # Config dataset
â”‚   â”‚   â”œâ”€â”€ coco_phobia.yaml
â”‚   â”‚   â””â”€â”€ augmentation.yaml
â”‚   â””â”€â”€ training/             # Config training
â”‚       â”œâ”€â”€ default.yaml
â”‚       â””â”€â”€ fast_test.yaml
â”‚
â”œâ”€â”€ src/                      # ğŸ’» Codice sorgente principale
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                 # ğŸ“Š Data Management (Membro A)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dataset.py        # PhobiaDataset class
â”‚   â”‚   â”œâ”€â”€ augmentation.py   # Custom augmentations
â”‚   â”‚   â”œâ”€â”€ preprocessing.py  # Data preprocessing
â”‚   â”‚   â””â”€â”€ download.py       # Script download datasets
â”‚   â”‚
â”‚   â”œâ”€â”€ models/               # ğŸ§  Model Architecture (Membro B)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ phobia_net.py     # PhobiaNet class
â”‚   â”‚   â”œâ”€â”€ backbone.py       # CNN backbone
â”‚   â”‚   â”œâ”€â”€ detection_head.py # Detection head
â”‚   â”‚   â””â”€â”€ loss.py           # Custom loss function
â”‚   â”‚
â”‚   â”œâ”€â”€ training/             # ğŸ‹ï¸ Training Logic (Membro B)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trainer.py        # Training loop
â”‚   â”‚   â”œâ”€â”€ validator.py      # Validation logic
â”‚   â”‚   â””â”€â”€ metrics.py        # mAP, IoU, etc.
â”‚   â”‚
â”‚   â”œâ”€â”€ inference/            # ğŸ¬ Deployment & Demo (Membro C)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ detector.py       # Inference engine
â”‚   â”‚   â”œâ”€â”€ nms.py            # Non-Maximum Suppression
â”‚   â”‚   â”œâ”€â”€ video_processor.py # Video frame processing
â”‚   â”‚   â””â”€â”€ blur.py           # ROI blurring
â”‚   â”‚
â”‚   â””â”€â”€ utils/                # ğŸ› ï¸ Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ visualization.py  # Plot bboxes, loss curves
â”‚       â”œâ”€â”€ logger.py         # Logging setup
â”‚       â””â”€â”€ bbox_utils.py     # IoU, NMS utilities
â”‚
â”œâ”€â”€ scripts/                  # ğŸ“œ Script eseguibili
â”‚   â”œâ”€â”€ download_data.sh      # Download datasets
â”‚   â”œâ”€â”€ train.py              # Script training principale
â”‚   â”œâ”€â”€ evaluate.py           # Valutazione modello
â”‚   â””â”€â”€ demo.py               # Demo interattiva
â”‚
â”œâ”€â”€ notebooks/                # ğŸ““ Jupyter Notebooks (solo per analisi)
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_model_testing.ipynb
â”‚   â””â”€â”€ 03_results_analysis.ipynb
â”‚
â”œâ”€â”€ tests/                    # ğŸ§ª Unit tests
â”‚   â”œâ”€â”€ test_dataset.py
â”‚   â”œâ”€â”€ test_model.py
â”‚   â””â”€â”€ test_loss.py
â”‚
â”œâ”€â”€ data/                     # ğŸ“¦ Dataset (gitignored)
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ annotations/
â”‚
â”œâ”€â”€ outputs/                  # ğŸ“ˆ Training outputs (gitignored)
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ videos/
â”‚
â”œâ”€â”€ docs/                     # ğŸ“š Documentazione
â”‚   â”œâ”€â”€ report.tex            # Report LaTeX
â”‚   â”œâ”€â”€ slides.pptx           # Presentazione
â”‚   â””â”€â”€ architecture.png      # Diagrammi
â”‚
â””â”€â”€ app/                      # ğŸŒ Demo App
    â”œâ”€â”€ streamlit_app.py      # Interfaccia Streamlit
    â””â”€â”€ utils.py              # Helper per app
```

---

## ğŸš€ Setup e Installazione

### 1. Clona il Repository
```bash
git clone https://github.com/your-team/PhobiaShield.git
cd PhobiaShield
```

### 2. Crea Virtual Environment
```bash
# Con conda (consigliato)
conda create -n phobiashield python=3.10
conda activate phobiashield

# Con venv
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows
```

### 3. Installa Dipendenze
```bash
pip install -r requirements.txt
pip install -e .  # Installa package in modalitÃ  development
```

### 4. Configura Weights & Biases
```bash
wandb login
# Inserisci la tua API key quando richiesto
```

### 5. Download Dataset
```bash
bash scripts/download_data.sh
```

---

## ğŸ’» Utilizzo

### Training

#### ModalitÃ  Base (con config di default)
```bash
python scripts/train.py
```

#### Con Hydra Configuration
```bash
# Training completo
python scripts/train.py model=tiny_yolo data=coco_phobia training=default

# Test veloce (poche epoch)
python scripts/train.py model=baseline training=fast_test

# Override parametri
python scripts/train.py training.epochs=50 training.batch_size=16 training.lr=0.001
```

#### Training su Google Colab (con GPU)
```python
# Nel notebook Colab
!git clone https://github.com/your-team/PhobiaShield.git
%cd PhobiaShield
!pip install -r requirements.txt
!pip install -e .

# Training
!python scripts/train.py training.device=cuda
```

### Evaluation
```bash
# Valuta il modello sul test set
python scripts/evaluate.py --checkpoint outputs/checkpoints/best_model.pth

# Calcola mAP
python scripts/evaluate.py --checkpoint outputs/checkpoints/best_model.pth --metric map
```

### Demo Interattiva
```bash
# Avvia interfaccia Streamlit
streamlit run app/streamlit_app.py

# Oppure con Gradio
python scripts/demo.py --video path/to/video.mp4
```

### Inferenza su Video
```bash
python scripts/demo.py \
    --video data/videos/trailer.mp4 \
    --checkpoint outputs/checkpoints/best_model.pth \
    --output outputs/videos/blurred_trailer.mp4 \
    --blur-intensity 15
```

---

## ğŸ‘¥ Team e Ruoli (Strategia "ALL-IN")

**Nuova organizzazione**: Collaborazione totale su Dataset & Report + Coding specializzato

### ğŸ“Š FASE CONDIVISA (TUTTI)

#### ğŸ—“ï¸ Day 0-2: Caccia al Dato
- **Membro 1**: ğŸ•·ï¸ Spider dataset
- **Membro 2**: ğŸ Snake dataset
- **Membro 3**: ğŸ©¸ Blood dataset

Ognuno scarica/pulisce/converte la propria classe â†’ merge in `all_phobias.zip`

#### ğŸ—“ï¸ Day 10-14: Report & Slide
- **Membro 1**: Sezione "Proposed Method" (Architettura + Loss)
- **Membro 2**: Sezione "Experimental Setup" (Augmentation + Training)
- **Membro 3**: Sezione "Application Results" (NMS + Demo)
- **TUTTI**: Introduction + Conclusions

---

### ğŸ’» FASE TECNICA (CODING)

### ğŸ—ï¸ Membro 1: THE ARCHITECT (Rete & Matematica)
**Focus**: Definire la struttura statica del cervello

**Tasks Principali**:
- âœ… Scrivere classe `PhobiaNet`
- âœ… Progettare layer sequence (Conv2d, BatchNorm, LeakyReLU)
- âš ï¸ **Task Critico**: Implementare **Loss Function** (MSE + BCE + CE)
- âœ… Analisi risultati e calcolo mAP

**File**: `src/models/phobia_net.py`, `src/models/loss.py`, `src/training/metrics.py`

**Branch**: `feature/model-architecture`

---

### ğŸ”„ Membro 2: THE TRAINER (Pipeline & Ottimizzazione)
**Focus**: Insegnare al cervello e gestire dati in ingresso

**Tasks Principali**:
- âœ… Scrivere Training Loop e DataLoader
- âœ… Gestire ciclo `for epoch in epochs`
- âš ï¸ **Task Critico**: Implementare **Data Augmentation** (rotations, zoom, color jitter)
- âœ… Monitorare training su W&B

**File**: `src/data/dataset.py`, `src/data/augmentation.py`, `scripts/train.py`

**Branch**: `feature/training-pipeline`

---

### ğŸ¬ Membro 3: THE ENGINEER (Inference & Demo)
**Focus**: Rendere i numeri visibili e creare l'applicazione

**Tasks Principali**:
- âœ… Scrivere Post-Processing (NMS) e Blurring
- âœ… Filtrare box sovrapposte
- âš ï¸ **Task Critico**: Creare **interfaccia Streamlit** e **Video Trailer**
- âœ… Montare demo finale

**File**: `src/inference/nms.py`, `src/inference/video_processor.py`, `app/streamlit_app.py`

**Branch**: `feature/inference-demo`

---

**ğŸ“š Documentazione Completa**: Vedi `docs/TEAM_ROLES.md` per dettagli workflow

---

## ğŸ“… Roadmap di Sviluppo (14 Giorni)

### Fase 1: Setup e Architettura (Giorni 1-4)
- [x] **Giorno 1**: Setup repo, ambiente, download dataset
- [ ] **Giorno 2-3**: Implementazione Loss Function + DataLoader
- [ ] **Giorno 4**: First training run (anche se modello non impara)

### Fase 2: Training e Integrazione (Giorni 5-9)
- [ ] **Giorno 5-6**: Debug training, monitoring loss
- [ ] **Giorno 7-8**: Overfitting check, model saving
- [ ] **Giorno 9**: Demo prep, video processing

### Fase 3: Showtime e Report (Giorni 10-14)
- [ ] **Giorno 10**: Benchmark (mAP calculation)
- [ ] **Giorno 11-12**: Slide presentation
- [ ] **Giorno 13-14**: Final polish, report LaTeX

---

## ğŸ¤ Contribuire

### Git Workflow

1. **Crea il tuo branch**:
```bash
git checkout -b feature/nome-feature
```

2. **Lavora sul tuo codice**:
```bash
git add .
git commit -m "feat: descrizione significativa"
```

3. **Push al tuo branch**:
```bash
git push origin feature/nome-feature
```

4. **Apri Pull Request** su GitHub quando pronto

### Commit Messages Convention
Usa [Conventional Commits](https://www.conventionalcommits.org/):
- `feat:` - Nuova feature
- `fix:` - Bug fix
- `docs:` - Documentazione
- `refactor:` - Refactoring codice
- `test:` - Test
- `chore:` - Maintenance

### Best Practices
- âœ… Testa il codice prima di fare commit
- âœ… Scrivi commit message descrittive
- âœ… Fai pull di `main` prima di creare nuovi branch
- âœ… Risolvi i conflitti localmente
- âœ… Usa `.gitignore` per non committare file pesanti

---

## ğŸ“Š Experiment Tracking con W&B

Il progetto usa Weights & Biases per tracciare esperimenti:

```python
import wandb

# Login (una sola volta)
wandb.login()

# Nel training script
wandb.init(
    project="phobiashield",
    name="tiny-yolo-v1",
    config={
        "learning_rate": 0.001,
        "epochs": 50,
        "batch_size": 16
    }
)

# Log metriche
wandb.log({"loss": loss, "mAP": map_score})
```

Dashboard W&B: `https://wandb.ai/your-team/phobiashield`

---

## ğŸ“ Note Importanti

### âš ï¸ Vincoli "From Scratch"
- âŒ NO ultralytics, detectron2, o librerie high-level detection
- âœ… SI PyTorch/TensorFlow puro per rete e loss
- âœ… Implementazione manuale di NMS
- âœ… Custom training loop

### ğŸ¯ Dataset Consigliati
- [COCO Subset (Spider, Snake)](https://cocodataset.org/)
- [Kaggle: Spider Detection Dataset](https://www.kaggle.com/)
- [Roboflow: Blood Detection](https://roboflow.com/)

### ğŸ”¥ GPU Recommendations
- **Google Colab**: Free T4 GPU (consigliato per training)
- **Kaggle Notebooks**: Free P100 GPU
- **Local**: NVIDIA GPU con CUDA support

---

## ğŸ“œ License

Questo progetto Ã¨ rilasciato sotto licenza MIT. Vedi `LICENSE` per dettagli.

---

## ğŸ™ Acknowledgments

- Ispirato dalla repository [MNIST-FDS](https://github.com/Mamiglia/MNIST-FDS)
- Dataset: COCO, Kaggle, Roboflow
- Framework: PyTorch, Weights & Biases, Hydra

---

## ğŸ“§ Contatti

Per domande o suggerimenti, apri un Issue su GitHub!

**Team PhobiaShield** - Dicembre 2025
